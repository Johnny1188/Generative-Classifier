{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Re**current **G**ener**A**tive C**L**assifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aq7wVuA6jSrM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import wandb\n",
        "\n",
        "from models.ReGAL import ReGALModel\n",
        "from utils.visualize import imshow_mnist, imshow_cifar10, plot_loss_history, show_samples\n",
        "from utils.data_loaders import get_mnist_data_loaders, get_cifar10_data_loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHvbR-A1EBTV",
        "outputId": "9ef0327a-63cd-4cc8-d868-9ff1d0763ad3"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 32\n",
        "%env \"WANDB_NOTEBOOK_NAME\" \"main.ipynb\"\n",
        "wandb.login()\n",
        "\n",
        "print(f\"... Running on {DEVICE} ...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train_mnist_loader, X_test_mnist_loader, classes_mnist = get_mnist_data_loaders(batch_size=BATCH_SIZE, root_path=\"data/\", download=False)\n",
        "X_train_cifar_loader, X_test_cifar_loader, classes_cifar = get_cifar10_data_loaders(batch_size=BATCH_SIZE, root_path=\"data/\", download=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_dict = {\n",
        "  \"classifier_cnn_layers\": (16,64,32),\n",
        "  \"classifier_cnn_input_dims\": (32,32,3),\n",
        "  \"classifier_cnn_output_dim\": 512,\n",
        "  \"classifier_head_layers\": (128,64,32,10),\n",
        "  \"generator_cnn_block_in_layer_shapes\": (512,312),\n",
        "  \"generator_prediction_in_layer_shapes\": (10,312),\n",
        "  \"generator_in_combined_main_layer_shapes\": (624,624,1024),\n",
        "  \"generator_cnn_trans_layer_shapes\": (32,32,16,3),\n",
        "  \"generator_input_dims\":(16,8,8),\n",
        "#   \"generator_input_dims\":(4,16,16),\n",
        "  \"classifier_lr\": 0.001,\n",
        "  \"classifier_weight_decay\": 1e-5,\n",
        "  \"generator_alpha\": 0.84,\n",
        "  \"generator_lr\": 0.004,\n",
        "  \"generator_weight_decay\": 1e-5,\n",
        "  \"eval_run_classifier_cnn_block_optimizer_lr\": 0.008,\n",
        "  \"eval_run_classifier_cnn_block_optimizer_weight_decay\": 1e-5,\n",
        "  \"eval_run_classifier_head_block_optimizer_lr\": 0.016,\n",
        "  \"eval_run_classifier_head_block_optimizer_weight_decay\": 1e-5,\n",
        "  \"device\": DEVICE\n",
        "}\n",
        "\n",
        "model = ReGALModel(config_dict=config_dict)\n",
        "# model.load_pretrained_params(\"model_parameters/model_parameters_dict_checkpoint_cifar10_26-12-2021_18.48.tar\", load_optimizers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb_run = wandb.init(\n",
        "    project=\"ReGAL\", entity=\"johnny1188\", config=config_dict,\n",
        "    tags=[\"pretraining\", \"gen-two-step-loss\"],\n",
        "    notes=f\"Generator's trans-cnn last layer using sigmoid\"\n",
        ")\n",
        "# wandb.watch(models=(\n",
        "#   model.classifier['cnn_block'], model.classifier['head_block'],\n",
        "#   model.generator['head_block'],\n",
        "#   model.generator['head_block'].dense_layers_stack_dict[\"in_classifier_prediction\"],\n",
        "#   model.generator['head_block'].dense_layers_stack_dict[\"in_combined_main_stack\"],\n",
        "#   model.generator['trans_cnn_block']), log=\"all\", log_freq=500\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_history, samples = model.pretrain(\n",
        "    epochs=30,\n",
        "    X_train_loader=X_train_cifar_loader,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    past_loss_history=None,\n",
        "    verbose=True,\n",
        "    is_wandb_run=True,\n",
        "    class_names=classes_cifar\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb_run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73hipcpyPec2"
      },
      "source": [
        "### Save pretrained model's parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "now = datetime.now()\n",
        "model.save_model_params(f\"model_parameters/model_parameters_dict_checkpoint_cifar10_{now.day}-{now.month}-{now.year}_{now.hour}.{now.minute}.tar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8gV2WxksUj4"
      },
      "source": [
        "# Analysis of pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "1s4QwZzysZVs",
        "outputId": "537b7578-71be-4baf-a611-6b89f7500984"
      },
      "outputs": [],
      "source": [
        "plot_loss_history(loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_samples(samples, 0, 0, 5, classes_cifar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(30,6))\n",
        "sns.heatmap(\n",
        "    model.generator[\"head_block\"].dense_layers_stack_dict[\"in_classifier_prediction\"][0].weight.detach().cpu().numpy().T,\n",
        "    xticklabels=15,\n",
        "    axes=ax\n",
        ")\n",
        "ax.set_ylabel(\"layer n-1 neurons\")\n",
        "ax.set_xlabel(\"layer n neurons\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(torch.mean(torch.abs(model.generator[\"head_block\"].dense_layers_stack_dict[\"in_combined_main_stack\"][0].weight[:,:312])))\n",
        "print(torch.mean(torch.abs(model.generator[\"head_block\"].dense_layers_stack_dict[\"in_combined_main_stack\"][0].weight[:,312:])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images = iter(X_train_cifar_loader)\n",
        "X, y = [part_of_data.to(model.device) for part_of_data in next(images)]\n",
        "\n",
        "z = model.classifier[\"cnn_block\"](X)\n",
        "z = z.reshape((BATCH_SIZE, model.classifier_cnn_output_dim_flattened))\n",
        "y_hat = model.classifier[\"head_block\"](z)\n",
        "\n",
        "# Normal reconstruction as in the pretraining and evaluation phases\n",
        "h = model.generator[\"head_block\"](z.detach(), y.int().detach())\n",
        "h_reshaped_for_cnn_block = torch.reshape(h, (BATCH_SIZE, *model.generator_cnn_input_dims))\n",
        "X_hat = model.generator[\"trans_cnn_block\"](h_reshaped_for_cnn_block)\n",
        "\n",
        "# one_hot = torch.zeros(y_hat.shape)\n",
        "# preds = torch.argmax(y_hat,dim=1)\n",
        "# for i in preds:\n",
        "#   one_hot[i,(preds[i] + 3) % len(one_hot[i])] = 1\n",
        "\n",
        "# Permutation of the last ten values of the generator's head block (=permuted categories)\n",
        "# h_2 = model.generator[\"head_block\"](z.detach(), torch.randint_like(y, 9).to(model.device))\n",
        "h_2 = model.generator[\"head_block\"](z.detach(), torch.zeros_like(y).to(model.device))\n",
        "# h_2 = model.generator[\"head_block\"](z.detach(), torch.zeros(y_hat.shape).to(model.device))\n",
        "h_reshaped_for_cnn_block_2 = torch.reshape(h_2, (BATCH_SIZE, *model.generator_cnn_input_dims))\n",
        "X_hat_2 = model.generator[\"trans_cnn_block\"](h_reshaped_for_cnn_block_2)\n",
        "\n",
        "h_3 = model.generator[\"head_block\"](torch.zeros(z.detach().shape).to(model.device), y.int().detach())\n",
        "h_reshaped_for_cnn_block_3 = torch.reshape(h_3, (BATCH_SIZE, *model.generator_cnn_input_dims))\n",
        "X_hat_3 = model.generator[\"trans_cnn_block\"](h_reshaped_for_cnn_block_3)\n",
        "\n",
        "imshow_cifar10(\n",
        "    X[0:5].cpu().detach(), \n",
        "    f\"Ground truth\",\n",
        "    w_color=True\n",
        ")\n",
        "imshow_cifar10(\n",
        "    X_hat[0:5].cpu().detach(), \n",
        "    f\"Gen\",\n",
        "    w_color=True\n",
        ")\n",
        "imshow_cifar10(\n",
        "    X_hat_2[0:5].cpu().detach(), \n",
        "    f\"Gen (permuted categories)\",\n",
        "    w_color=True\n",
        ")\n",
        "imshow_cifar10(\n",
        "    X_hat_3[0:5].cpu().detach(), \n",
        "    f\"Gen (zeroed-out cnn input)\",\n",
        "    w_color=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5lRr7Febp-b"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.classifier[\"head_block\"].dense_layers_stack[6].weight.register_hook(lambda grad_in: grad_in * 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPQHAWNh5Mgw"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, X_test_loader, max_reconstruction_steps=10, max_batches=200):\n",
        "    model.turn_model_to_mode(mode=\"eval\")\n",
        "\n",
        "    loss_func_classification = nn.CrossEntropyLoss()\n",
        "    classification_loss_history = []\n",
        "\n",
        "    for i,data in enumerate(X_test_loader):\n",
        "        X, y = [part_of_data.to(DEVICE) for part_of_data in data]\n",
        "\n",
        "        y_hat = model(X, max_reconstruction_steps=max_reconstruction_steps)\n",
        "\n",
        "        classification_loss_history.append( loss_func_classification(y_hat, y).detach().cpu().item() )\n",
        "        if i > max_batches: break\n",
        "\n",
        "    return(classification_loss_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "6FyraZL35r5l",
        "outputId": "e7d1c7a6-eb98-4127-adf7-4e3b0e46ec8e"
      },
      "outputs": [],
      "source": [
        "classification_loss_history_wout_reconstruction = eval_model(model, X_test_loader=X_test_cifar_loader, max_reconstruction_steps=0, max_batches=120)\n",
        "classification_loss_history_w_reconstruction = eval_model(model, X_test_loader=X_test_cifar_loader, max_reconstruction_steps=20, max_batches=120)\n",
        "\n",
        "print(f\"\"\"-----\\nMean classification loss:\n",
        ">>> with reconstruction: {round(sum(classification_loss_history_w_reconstruction)/len(classification_loss_history_w_reconstruction), 4)}\n",
        ">>> without reconstruction: {round(sum(classification_loss_history_wout_reconstruction)/len(classification_loss_history_wout_reconstruction), 4)}\\n-----\\n\"\"\"\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(classification_loss_history_w_reconstruction, label=\"with reconstruction\")\n",
        "plt.plot(classification_loss_history_wout_reconstruction, label=\"without reconstruction\")\n",
        "plt.legend()\n",
        "plt.title(\"Classification loss history\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cXuZbZ-ijYyF",
        "q7fPzuEtSwGR",
        "KRGMHyTeQ7RY",
        "ZskRT7uhjr7r",
        "LIBwcuXvjxJ1",
        "9k0BjbB_opsC",
        "OmykYP4-xZac",
        "2CGy2JNabcb8",
        "jfEvX78sNQCg"
      ],
      "name": "main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
